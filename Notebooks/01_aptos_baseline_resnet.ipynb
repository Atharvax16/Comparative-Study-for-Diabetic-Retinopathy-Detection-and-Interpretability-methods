{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288804f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca86a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "APTOS_ROOT = r\"C:\\DCU\\Thesis\\data\\APTOS\"\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(APTOS_ROOT, \"train_images\")\n",
    "VAL_IMG_DIR   = os.path.join(APTOS_ROOT, \"val_images\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(APTOS_ROOT, \"train_1.csv\")\n",
    "VAL_CSV   = os.path.join(APTOS_ROOT, \"valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422a7a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis\n",
      "0    1434\n",
      "2     808\n",
      "1     300\n",
      "4     234\n",
      "3     154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_CSV)\n",
    "val_data = pd.read_csv(VAL_CSV)\n",
    "\n",
    "train_data.head()\n",
    "print(train_data['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd612d",
   "metadata": {},
   "source": [
    "# TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b324ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485,0.456,0.406)\n",
    "IMAGENET_STD = (0.229,0.224,0.225)\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a3d7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APTOSDataset(Dataset):\n",
    "    def __init__(self, data, img_dir, transform):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_id = row[\"id_code\"]\n",
    "        label = int(row[\"diagnosis\"])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_id + \".png\")\n",
    "        if not os.path.exists(img_path):\n",
    "            img_path = os.path.join(self.img_dir, img_id + \".jpg\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962334f",
   "metadata": {},
   "source": [
    "## DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c757ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = APTOSDataset(train_data, TRAIN_IMG_DIR, train_tfms)\n",
    "val_ds   = APTOSDataset(val_data, VAL_IMG_DIR, val_tfms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=32, shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=64, shuffle=False, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe34893",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02b78451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 5)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc260a",
   "metadata": {},
   "source": [
    "## TRAIN AND EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5168d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model,loader,train = True):\n",
    "    model.train() if train else model.eval()\n",
    "    all_labels,all_probs,all_preds = [],[],[]\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        \n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits,y)\n",
    "            \n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        probs = torch.softmax(logits,dim = 1).detach().cpu().numpy()\n",
    "        preds = np.argmax(probs,axis = 1)\n",
    "        \n",
    "        all_probs.append(probs)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(y.cpu().numpy())\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    \n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs, multi_class=\"ovr\")\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "\n",
    "    return avg_loss, acc, auc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8949c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Train: loss=0.7148, acc=0.7464, auc=0.8779154154621027\n",
      "Val  : loss=0.5976, acc=0.7705, auc=0.914690085327511\n",
      "Confusion Matrix:\n",
      " [[170   0   1   0   1]\n",
      " [  2   6  29   0   3]\n",
      " [  3   1  85   7   8]\n",
      " [  1   0   6   7   8]\n",
      " [  0   0  12   2  14]]\n",
      "\n",
      "Epoch 2/5\n",
      "Train: loss=0.4715, acc=0.8154, auc=0.9416695198896562\n",
      "Val  : loss=0.4927, acc=0.8306, auc=0.9413123859324124\n",
      "Confusion Matrix:\n",
      " [[171   1   0   0   0]\n",
      " [  3  24  12   0   1]\n",
      " [  2   5  83  13   1]\n",
      " [  0   1   6  12   3]\n",
      " [  0   2   7   5  14]]\n",
      "\n",
      "Epoch 3/5\n",
      "Train: loss=0.4274, acc=0.8399, auc=0.9517268879327784\n",
      "Val  : loss=0.4885, acc=0.7978, auc=0.9456931759919686\n",
      "Confusion Matrix:\n",
      " [[171   1   0   0   0]\n",
      " [  2  18  19   0   1]\n",
      " [  4   4  95   1   0]\n",
      " [  1   0  18   3   0]\n",
      " [  0   1  19   3   5]]\n",
      "\n",
      "Epoch 4/5\n",
      "Train: loss=0.3631, acc=0.8635, auc=0.9648043471962111\n",
      "Val  : loss=0.5036, acc=0.8306, auc=0.9400944112061662\n",
      "Confusion Matrix:\n",
      " [[171   1   0   0   0]\n",
      " [  0  19  18   0   3]\n",
      " [  1   4  89   7   3]\n",
      " [  0   0   8   8   6]\n",
      " [  0   1   8   2  17]]\n",
      "\n",
      "Epoch 5/5\n",
      "Train: loss=0.3116, acc=0.8765, auc=0.9744286525124132\n",
      "Val  : loss=0.5616, acc=0.8279, auc=0.9386636325587496\n",
      "Confusion Matrix:\n",
      " [[171   1   0   0   0]\n",
      " [  0  22  17   0   1]\n",
      " [  1   8  91   1   3]\n",
      " [  0   1  13   4   4]\n",
      " [  0   2  11   0  15]]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_acc, tr_auc, _ = run_epoch(model, train_loader, train=True)\n",
    "    va_loss, va_acc, va_auc, va_cm = run_epoch(model, val_loader, train=False)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc:.4f}, auc={tr_auc}\")\n",
    "    print(f\"Val  : loss={va_loss:.4f}, acc={va_acc:.4f}, auc={va_auc}\")\n",
    "    print(\"Confusion Matrix:\\n\", va_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"checkpoints/aptos_resnet50_baseline.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7767240",
   "metadata": {},
   "source": [
    "We can observe that after training and validation there is a rise in accuracy,might be a slight overfit but "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e7011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
